{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This script produces visualizations of the uncalibrated neural likelihood surfaces with 95% approximate confidence regions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Polygon as patch_polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load uncalibrated neural likelihood surfaces\n",
    "image_size = 25\n",
    "image_name = str(image_size) + \"_by_\" + str(image_size)\n",
    "local_folder = \"/home/juliatest/Dropbox/likelihood_free_inference/neural_likelihood/gaussian_process\"\n",
    "version = \"final_version\"\n",
    "uncalibrated_neural_likelihood_surfaces_file =(local_folder + \"/evaluate_nn/produce_neural_likelihood_surfaces/data/\" + image_name\n",
    "                                        + \"/\" + version + \"/uncalibrated/single/reps/200/\"\n",
    "                                        \"/uncalibrated_neural_likelihood_surfaces_9_by_9_density_25_by_25_image_200.npy\")\n",
    "uncalibrated_neural_likelihood_surfaces = np.load(uncalibrated_neural_likelihood_surfaces_file)\n",
    "\n",
    "number_of_parameters = 100\n",
    "number_of_reps = 200\n",
    "#first column is variance and second is lengthscale\n",
    "parameter_matrix = np.load((local_folder + \"/evaluate_nn/generate_data/data/\" + image_name + \n",
    "                            \"/single/reps/200/evaluation_parameters_9_by_9_density_\" + image_name + \"_200.npy\"))\n",
    "parameter_matrix = parameter_matrix[:,0,:]\n",
    "possible_lengthscales = [round(.05*i,2) for i in range(1, 41)]\n",
    "possible_variances = [round(.05*i,2) for i in range(1, 41)]\n",
    "#Cut off value that corresponds to 95 percent coverage for chi-distribution with 2 degrees of freedom (dimension of parameter space)\n",
    "C = 5.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function produces the 95 percent approximate confidence region over the parameter grid for a given neural likelihood surface\n",
    "    #parameters:\n",
    "        #neural_likelihood_surface: 40 by 40 matrix, neural likelihood surface for a given realization of the GP (uncalibrated or calibrated)\n",
    "        #possible_lengthscales: values of lengthscales on the parameter grid\n",
    "        #possible_variances: values of variances on the parameter grid\n",
    "        #C: cut off value that corresponds to 95 percent coverage for chi-distribution with 2 degrees of freedom (dimension of parameter space)\n",
    "def produce_neural_likelihood_confidence_region(neural_likelihood_surface, possible_lengthscales, possible_variances, C):\n",
    "\n",
    "    max_field_value = np.log(np.max(neural_likelihood_surface))\n",
    "    field_difference = 2*(max_field_value - np.log(neural_likelihood_surface))\n",
    "    confidence_grid = np.where(field_difference <= C, 1, 0)\n",
    "\n",
    "    variance_values = []\n",
    "    lengthscale_values = []\n",
    "    \n",
    "    for i in range(0, confidence_grid.shape[0]):\n",
    "        if(np.array(np.where((confidence_grid[i,:]) == 1)).any()):\n",
    "            #min_val = (np.array(np.where((confidence_grid[i,:]) == 1))).min()\n",
    "            max_val = (np.array(np.where((confidence_grid[i,:]) == 1))).max()\n",
    "            variance_values.append(possible_variances[i])\n",
    "            lengthscale_values.append(possible_lengthscales[max_val])\n",
    "\n",
    "    for i in range((confidence_grid.shape[0] - 1), 0, -1):\n",
    "        if(np.array(np.where((confidence_grid[i,:]) == 1)).any()):\n",
    "            min_val = (np.array(np.where((confidence_grid[i,:]) == 1))).min()\n",
    "            variance_values.append(possible_variances[i])\n",
    "            lengthscale_values.append(possible_lengthscales[min_val])\n",
    "\n",
    "    confidence_region = np.zeros((len(variance_values),2))\n",
    "    confidence_region[:,0] = lengthscale_values\n",
    "    confidence_region[:,1] = variance_values\n",
    "\n",
    "    return confidence_region\n",
    "\n",
    "#Produce visualization of neural likelihood surface with 95 percent approximate confidence region\n",
    "    #parameters:\n",
    "        #neural_likelihood_surface: 40 by 40 matrix, neural likelihood surface for a given realization of the GP (calibrated or uncalibrated)\n",
    "        #possible_lengthscales: values of lengthscales on the parameter grid\n",
    "        #possible_variances: values of variances on the parameter grid\n",
    "        #C: cut off value that corresponds to 95 percent coverage for chi-distribution with 2 degrees of freedom (dimension of parameter space)\n",
    "        #true_lengthscale: the lengthscale which generated the realization of the gp\n",
    "        #true_variance: the variance which generated the realization of the gp\n",
    "        #irep: the number referring to the specific realization for the given parameter on the grid\n",
    "        #constant: the color scale for the visualization is set to span the maximum value of the surface and the maximum value of the surface minuse constant\n",
    "        #single_or_multi: str that indicates which type (single realization or multiple realization)\n",
    "def produce_neural_confidence_region_surface(neural_likelihood_surface, possible_lengthscales, possible_variances, C, \n",
    "                                             true_lengthscale, true_variance, irep, constant, single_or_multi):\n",
    "\n",
    "    confidence_region = produce_neural_likelihood_confidence_region(neural_likelihood_surface, possible_lengthscales, possible_variances, C)\n",
    "    polygon_figure = patch_polygon(confidence_region, facecolor = \"none\", edgecolor = \"black\", linewidth = 5)\n",
    "    fig, ax = plt.subplots(figsize = (10,10))\n",
    "    x = np.linspace(.05, 2, 40)\n",
    "    y = np.linspace(.05, 2, 40)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    neural_likelihood_surface[neural_likelihood_surface == np.inf] == np.min(neural_likelihood_surface[neural_likelihood_surface != np.inf])\n",
    "    Z = np.log(neural_likelihood_surface)\n",
    "    Z = Z.reshape((40, 40))\n",
    "    max_indices = np.unravel_index(np.argmax(Z, axis=None), Z.shape)\n",
    "    max_lengthscale = possible_lengthscales[max_indices[1]]\n",
    "    max_variance = possible_variances[max_indices[0]]\n",
    "    cp = ax.contourf(X, Y, Z, vmin = (np.amax(Z) -constant), vmax = np.amax(Z), levels = 12000)\n",
    "    ax.add_patch(polygon_figure)\n",
    "    ax.scatter(true_lengthscale, true_variance, s = 600, marker = \"*\", c = \"black\")\n",
    "    ax.scatter(max_lengthscale, max_variance, s = 600, marker = \"o\", c= \"red\")\n",
    "    legend_elements = [Line2D([0], [0], marker='*', color='w', label='True',\n",
    "                          markerfacecolor='black', markersize=40), \n",
    "                          Line2D([0], [0], marker='o', color='w', label='Estimate',\n",
    "                          markerfacecolor='red', markersize=30), Line2D([0], [0], marker='_', color='black', label='95% CR',\n",
    "                          markerfacecolor='none', markersize=40, linewidth = 8)]\n",
    "    ax.legend(handles = legend_elements, facecolor='white', framealpha=1, fontsize=\"25\")\n",
    "    ax.set_xlabel(\"length scale\", fontsize = 40)\n",
    "    ax.set_ylabel(\"variance\", fontsize = 40)\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.xticks(fontsize =20)\n",
    "    plt.title(\"Neural Likelihood\", fontsize = 45)\n",
    "    plt.tight_layout()\n",
    "    fig_name = (local_folder + \n",
    "                \"/evaluate_nn/visualizations/visualize_approximate_confidence_regions/visualizations/neural_likelihood/\" + \n",
    "                version + \"/uncalibrated/\" + single_or_multi + \"/reps/200/\" \n",
    "                + str(constant) + \"_uncalibrated_neural_likelihood_approximate_confidence_region_95_variance_\"\n",
    "                + str(round(true_variance, 2))\n",
    "     + \"_lengthscale_\" + str(round(true_lengthscale, 2)) + \"_rep_\" + str(irep) + \".png\")\n",
    "    plt.savefig(fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single realization case\n",
    "#These are the indices for the 4 by 4 grid over the parameter space starting at (.4,.4) and increasing by increments of .4\n",
    "indices = [10,12,14,16,28,30,32,34,46,48,50,52,64,66,68,70]\n",
    "constant = 10\n",
    "\n",
    "for ipred in [30]:\n",
    "    for irep in range(12,13):\n",
    "        #first column is variance\n",
    "        current_lengthscale = parameter_matrix[ipred,1]\n",
    "        current_variance = parameter_matrix[ipred,0]\n",
    "        produce_neural_confidence_region_surface(uncalibrated_neural_likelihood_surfaces[ipred, irep,:,:], possible_lengthscales, possible_variances, C,\n",
    "                                          current_lengthscale, current_variance, irep, constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple realization case\n",
    "multi_uncalibrated_neural_likelihood_surfaces_file =(local_folder + \"/evaluate_nn/produce_neural_likelihood_surfaces/data/\" + image_name\n",
    "                                        + \"/\" + version + \"/uncalibrated/multi/5/reps/200\" +\n",
    "                                        \"/uncalibrated_neural_likelihood_surfaces_9_by_9_density_25_by_25_multi_5_200.npy\")\n",
    "multi_uncalibrated_neural_likelihood_surfaces = np.load(multi_uncalibrated_neural_likelihood_surfaces_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple realization case\n",
    "#These are the indices for the 4 by 4 grid over the parameter space starting at (.4,.4) and increasing by increments of .4\n",
    "indices = [10,12,14,16,28,30,32,34,46,48,50,52,64,66,68,70]\n",
    "constant = 10\n",
    "single_or_multi = \"multi/5\"\n",
    "\n",
    "for ipred in indices:\n",
    "    for irep in range(0,5):\n",
    "        #first column is variance\n",
    "        current_lengthscale = parameter_matrix[ipred,1]\n",
    "        current_variance = parameter_matrix[ipred,0]\n",
    "        produce_neural_confidence_region_surface(multi_uncalibrated_neural_likelihood_surfaces[ipred, irep,:,:],\n",
    "                                                 possible_lengthscales, possible_variances, C,\n",
    "                                                 current_lengthscale, current_variance, irep, constant, single_or_multi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gp-env-conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
